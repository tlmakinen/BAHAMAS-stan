{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampling for BAHAMAS latent variables\n",
    "\n",
    "In the BAHAMAS hierarchical model, two parameters of interest---each supernova's color, $c$, and population mean of color $c_*$ are analytically margninalized out to aid in computation of the partially-collapsed Gibbs sampler (PCGS). As a result, we do not have access to these values in the form of posterior distributions.\n",
    "\n",
    "The problem at hand is that we want to look into our model and see how the shapes of our $c_i$ and population mean $c_*$ affect our inference (since STEVE showed a bias for certain shapes). We want to know if we want to change our assumption of distribution of $c_i$ from **gaussian** to **skew-gaussian**. \n",
    "\n",
    "In order to figure out these shapes, we need to rewrite a Gibbs Sampler by hand, following the work of Shariff et al (2016) https://arxiv.org/pdf/1510.05954.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules we need for the analysis\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "# turn off annoying write warnings in pandas\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bahamas modules\n",
    "import cosmology\n",
    "import vanilla_log_likelihood as vanilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings Sampler\n",
    "\n",
    "Before we can take Gibbs step-by-step, we need to define a MH sampler that will fit into our algorithm below\n",
    "\n",
    "Quick overview of MH sampling:\n",
    "We're interested in a target distribution $P(x)$. Let $f(x)$ be a function proportional to $P(x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(f, x_init, n_iters, variance):\n",
    "    \n",
    "    # Using our x_init, initialize our walker and chain\n",
    "    x = x_init    \n",
    "    x_chain = []\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        \n",
    "        # each iteration, generate a candidate x from the proposal distribution--gaussian in this case\n",
    "        x_candidate = np.random.normal(loc = x_init, scale=variance)        \n",
    "        acc_ratio = f(x_candidate) / f(x)\n",
    "        \n",
    "        # now accept or reject the x candidate. Do this by sampling from U(0,1)        \n",
    "        u = np.random.uniform(low=0, high=1)\n",
    "        \n",
    "        if acc_ratio >= u:\n",
    "            x_chain.append(x_candidate)\n",
    "            x = x_candidate   # move our walker onwards\n",
    "        \n",
    "        else:\n",
    "            x_chain.append(x)  # stay in place if acceptance fraction not high enough\n",
    "            \n",
    "        return x_chain     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our sample, we're going to make definitions out of every step described in Hik et al. Then, we can iterate over all steps in sequence at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simga_D_latent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Use MH to sample $\\mathscr{C}$ from $p(\\Sigma_D, \\mathscr{B}. \\mathscr{C}, | \\hat{\\mathscr{D}}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cosmo(data, cov_D, pars):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_B():\n",
    "    B_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to sample our latent variable vector, $D_i = \\{M_{i}^{\\epsilon}, x_{1i}, c_1\\}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_D():\n",
    "    \n",
    "    D_star_new = np.random.normal(loc=k_star, scale = sig_k, size=(3,1))   # generate new population mean vector\n",
    "    \n",
    "    D_new = np.random.normal(loc=mu_A, scale=sig_A, size=(3,1))   # generate new sampled data vector\n",
    "    \n",
    "    # update values\n",
    "    D_star = D_star_new\n",
    "    D = D_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
